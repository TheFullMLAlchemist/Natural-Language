{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = pd.read_csv(\"../input/preprocessed-with-emoji/preprocessed_with_emoji.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8a6c788122f68e2aeaace5052f92cce82a3deb4"
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "97e08cee19ca6d7104cef045c095ce4e4c912dd9"
      },
      "cell_type": "code",
      "source": "# Starting with the CountVectorizer/TfidfTransformer approach...\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\ncvec = CountVectorizer(stop_words='english', min_df=.00005, max_df=.5, ngram_range=(1,3))\ncvec",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "add6fe74c736ba263397dbc83414d12b8988efcc"
      },
      "cell_type": "code",
      "source": "# setting up our CountVectorizer\ncvec.fit(df.Comment)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "662a0a9f0c0799e8c1d34df86729e235636c893b"
      },
      "cell_type": "code",
      "source": "len(cvec.vocabulary_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a63f26f5f870eef6e66b030b3d1ed0d34f8877f9"
      },
      "cell_type": "code",
      "source": "# transform the document into a “bag of words” representation\ncvec_counts = cvec.transform(df.Comment)\nprint('sparse matrix shape:', cvec_counts.shape)\nprint('nonzero count:', cvec_counts.nnz)\nprint('sparsity: %.2f%%' % (100.0 * cvec_counts.nnz / (cvec_counts.shape[0] * cvec_counts.shape[1])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e48e4c2868abd00f640d813fd1389e5cac6eb3f4"
      },
      "cell_type": "code",
      "source": "# top 20 most common terms \n\nocc = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist()\ncounts_df = pd.DataFrame({'term': cvec.get_feature_names(), 'occurrences': occ})\ncounts_df.sort_values(by='occurrences', ascending=False).head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dbd7ee113e730e2b00e1f2956954bb1d4da429d7"
      },
      "cell_type": "code",
      "source": "# using the TfidfTransformer to calculate the weights for each term in each document \n\ntransformer = TfidfTransformer()\ntransformed_weights = transformer.fit_transform(cvec_counts)\ntransformed_weights",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f78d4c5566fbc902b8616f981c5bc7af0ed0a65f"
      },
      "cell_type": "code",
      "source": "# top 20 terms by average tf-idf weight:\n\nweights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\nweights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'weight': weights})\nweights_df.sort_values(by='weight', ascending=False).head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4456252fe14124201abd1de202e883b45bd69ab"
      },
      "cell_type": "code",
      "source": "# using the TfidfVectorizer class\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntvec = TfidfVectorizer(min_df=0.00005, max_df=.5, stop_words='english', ngram_range=(1,1))\ntvec_weights = tvec.fit_transform(df.Comment)\nweights = np.asarray(tvec_weights.mean(axis=0)).ravel().tolist()\nweights_df = pd.DataFrame({'term': tvec.get_feature_names(), 'weight': weights})\nweights_df.sort_values(by='weight', ascending=False).head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9441722f5a2598aa3ad3f70091870f801c28ff5"
      },
      "cell_type": "code",
      "source": "tvec_weights[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e5e4b05f33b39ceba068b051ef71e04468b89e64"
      },
      "cell_type": "code",
      "source": "X_train = tvec_weights[:10000]\ny_train = df[\"Agg_Level\"][:10000]\n\nX_test = tvec_weights[10000:]\ny_test = df[\"Agg_Level\"][10000:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d953f29a60a0e21a9f91ec83aa93034ad46ff8e9"
      },
      "cell_type": "code",
      "source": "import sklearn\nsklearn.preprocessing.normalize(X_train, norm='l2', axis=1, copy=True, return_norm=False)\nsklearn.preprocessing.normalize(X_test, norm='l2', axis=1, copy=True, return_norm=False)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1356f1a2d279ea0d3293b1f9919ee1e6fec44d94",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Naive bayes Model\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "52ece49bfd52e518a4f1e7caf96f1e8e977cfac4"
      },
      "cell_type": "code",
      "source": "predicted = clf.predict(X_test)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "798bd9972b4caef26dfff89f796cf0417c202779",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bda69a40f9fe0c7a00818fc9ec6117c9e6a3b27f"
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\nmetrics.accuracy_score(y_test, predicted, normalize=True, sample_weight=None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d0f3cf9a54d51e5e90196e86d1e228440732cef",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# # Support Vector Machine Model\n# from sklearn import svm\n# clf = svm.SVC().fit(X_train, y_train)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14f3e726bc72720c3b25512f5e9f8fcea2a91b2b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# predicted_svm = clf.predict(X_test)\n# np.mean(predicted_svm == y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f5a34d0788b67b9563ae05ff47c43e8f820592a"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb4dbcedff477c487b74c7fea3a08557958d25c8"
      },
      "cell_type": "code",
      "source": "predicted_RandomForestClassifier = classifier.predict(X_test)\nmetrics.accuracy_score(y_test, predicted_RandomForestClassifier, normalize=True, sample_weight=None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "832d3c59d629be8f81ffaa53b99d3702147ea13b"
      },
      "cell_type": "code",
      "source": "# using xgboost classifier\nfrom xgboost import XGBClassifier\n# fit model into training data\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nmetrics.accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "787d1a6b735b17022110debe3a07ffb031878c5c"
      },
      "cell_type": "code",
      "source": "import xgboost",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f832a443953848aa74c98c9ceed368403681ac8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# #LightGBM Regressor\n# import lightgbm\n# from lightgbm import LGBMRegressor\n# from lightgbm import LGBMClassifier\n# model = LGBMRegressor(boosting_type='gbdt', objective='multiclass',num_class=3,\n#                       num_iteration=10000,num_leaves=31,is_enable_sparse='true',\n#                       tree_learner='data',min_data_in_leaf=600,max_depth=4, learning_rate=0.1, \n#                       n_estimators=675, max_bin=255, subsample_for_bin=50000, min_split_gain=5, \n#                       min_child_weight=5, min_child_samples=10, subsample=0.995, subsample_freq=1, \n#                       colsample_bytree=1, reg_alpha=.5, reg_lambda=.5, seed=0, nthread=-1, silent=True)\n\n# #Fit to training data\n# model.fit(X_train, y_train)\n# #Generate Predictions\n# y_pred=model.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf42c869cfa81292af2ac6a9fccee36ee0afab76",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# classes = \"0,1,2\".split(',')\n# subm = pd.DataFrame(y_pred, columns=classes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2239d9c4bc91fce6d84e5103749a8c2bc6f6cc42",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# y_prediction = []\n# for i in range(len(subm)):\n#     if max(subm['0'][i], subm['1'][i], subm['2'][i]) == subm['0'][i]:\n#         y_prediction.append(0)\n#     elif max(subm['0'][i], subm['1'][i], subm['2'][i]) == subm['1'][i]:\n#         y_prediction.append(1)\n#     elif max(subm['0'][i], subm['1'][i], subm['2'][i]) == subm['2'][i]:\n#         y_prediction.append(1)\n        \n# np.mean(y_prediction == y_test)        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "885bdf62c20bcd10c0d1890600982a48947bf828"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nsmreg_model = LogisticRegression(multi_class=\"multinomial\", solver='lbfgs')\n\nsmreg_model.fit(X_train, y_train)\n\npredicted_LR = smreg_model.predict(X_test)\nmetrics.accuracy_score(y_test, predicted_LR, normalize=True, sample_weight=None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c68f9a6f8f2202a7f91ebca23e6918b0d79846ea"
      },
      "cell_type": "code",
      "source": "# def cross_validate_xgb(params, x_train, y_train, kf, verbose=True, verbose_eval=50):\n#     start_time=time.time()\n#     nround=[]\n#     # the prediction matrix need to contains 3 columns, one for the probability of each class\n#     train_pred = np.zeros((x_train.shape[0],3))\n    \n#     # use the k-fold object to enumerate indexes for each training and validation fold\n#     for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train)):\n#         x_train_kf, x_val_kf = x_train[train_index, :], x_train[val_index, :]\n#         y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n        \n#         d_train = xgboost.DMatrix(x_train_kf, y_train_kf)\n#         d_val=xgboost.DMatrix(x_val_kf, y_val_kf)\n\n#         watchlist= [(d_train, \"train\"), (d_val, 'val')]\n#         bst = xgboost.train(params=params, dtrain=d_train, num_boost_round=3000, early_stopping_rounds=100,\n#                             evals=watchlist, verbose_eval=verbose_eval)        \n        \n#         y_val_kf_preds=bst.predict(d_val, ntree_limit=bst.best_ntree_limit)\n#         nround.append(bst.best_ntree_limit)\n        \n#         train_pred[val_index] += y_val_kf_preds\n        \n#         fold_cv = log_loss(y_val_kf, y_val_kf_preds)\n#         if verbose:\n#             print('fold cv {} log_loss score is {:.6f}'.format(i, fold_cv))\n        \n#     cv_score = log_loss(y_train, train_pred)\n    \n#     if verbose:\n#         print('cv log_loss score is {:.6f}'.format(cv_score))    \n#         end_time = time.time()\n#         print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n#     return cv_score # for the purpose of bayesian optimisation, we only need to return the CV score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0c734975e089c0765f45896773e85ca197b308b1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# from sklearn.metrics import log_loss\n# from sklearn.model_selection import cross_val_score, cross_val_predict\n# from sklearn.model_selection import StratifiedKFold\n# from bayes_opt import BayesianOptimization\n# import time\n# # the bayesian optimisation library throws a lot of warning message, so for readability we disable warning in this notebook.\n# # *NOT* encouraged if you want to find out what is going on under the cover :) \n# import warnings\n# warnings.filterwarnings(\"ignore\") \n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# from subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# # Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ffaeb631d0f36fd587d0c3d3ce39681750cfef9a"
      },
      "cell_type": "code",
      "source": "# params={'max_depth':(9,15),\n#         'learning_rate':(0.0525,0.0544),\n#         'subsample': (0.760, 0.790),\n#         'colsample_bytree': (0.4087, 0.4163)\n#        }",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5562229a208f880f4d953e25e52a1617464a48e5"
      },
      "cell_type": "code",
      "source": "# # reload(xgb_wrapper)\n# def xgbcv_func(max_depth, learning_rate, subsample, colsample_bytree, nthread=4, seed=0):\n#     params = {\n#         \"objective\" : \"multi:softprob\",\n#         \"num_class\" : 3,\n#         \"tree_method\" : \"auto\",\n#         \"eval_metric\" : \"mlogloss\",\n#         \"nthread\": nthread,\n#         \"seed\" : 0,\n#         'silent': 1,\n\n#         \"eta\":learning_rate,  # default 0.3\n#         \"max_depth\" : int(max_depth), # default 6\n#         \"subsample\" : subsample, # default 1\n#         \"colsample_bytree\" : colsample_bytree, # default 1\n#     }\n    \n#     # for a more ideal out-of-fold model prediction for this dataset, we use 10-fold CV\n#     kf=StratifiedKFold(n_splits=10, shuffle=True, random_state=2017)\n    \n#     # we will disable all the verbose setting in this functional call, so that we don't have too much information \n#     # to read during the bayesian optimisation process.\n#     return 1-cross_validate_xgb(params, X_train, y_train, kf, verbose=False, verbose_eval=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "998e7b24949235950986aa434c5df18f0d2a430f"
      },
      "cell_type": "code",
      "source": "# xgb_bo=BayesianOptimization(xgbcv_func, params)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fff966b1425121e0de8f7901705a98696358e53",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# xgb_bo.maximize(init_points=5, n_iter=50)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b7d90358e570febdd64e361acb6faa8076b8c558"
      },
      "cell_type": "code",
      "source": "#  Value  |   colsample_bytree |   learning_rate |   max_depth |   subsample |\n# 0.07329 |             0.4163 |          0.0525 |      9.4621 |      0.7490 |\n# 0.07432 |             0.4045 |          0.0522 |      8.7714 |      0.7610 |",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9dbd506e198568cefc1056b36b3c8f489429a614"
      },
      "cell_type": "code",
      "source": "xgb_parameters = {\n    \"objective\" : \"multi:softprob\",\n    \"num_class\" : 3,\n    \"tree_method\" : \"auto\",\n    \"eval_metric\" : \"mlogloss\",\n    \"nthread\": 5,\n    \"seed\" : 0,\n    'silent': 1,\n\n    \"eta\":0.0522,  # default 0.3\n    \"max_depth\" : 9, # default 6\n    \"subsample\" : 0.7610, # default 1\n    \"colsample_bytree\" : 0.4045, # default 1\n    \"gamma\": 0.5\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1cf9eb89c8aa325b0e470c2d98367d2fa653d007"
      },
      "cell_type": "code",
      "source": "model = XGBClassifier(**xgb_parameters)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nmetrics.accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0833c28c6733ebdc3146b53d3b089b30247d1382"
      },
      "cell_type": "code",
      "source": "model = XGBClassifier(**xgb_parameters)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_train)\nnp.mean(y_pred == y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "34a1832693e497957c2431de10b22d6bcebce399"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}